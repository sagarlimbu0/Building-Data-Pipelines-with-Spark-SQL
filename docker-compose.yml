# # Network connection between services
# # by default the services are connected via `default` network
# # Here, we will configure the default network; `custom-driver`

# version: "3"
# services:

#   #####################
#   # 1. postgres service
#   postgres:
#     image: postgres:14.1-alpine
#     environment:
#       - POSTGRES_USER=airflow
#       - POSTGRES_PASSWORD=airflow
#       - POSTGRES_DB=airflow
#     logging:
#       options:
#         max-size: 10m
#         max-file: "3"
#     volumes:
#       - "./postgres_db:/var/lib/postgresql/data:rw"

#     ports:
#       - '5432:5432'
#   # networks:
#   #   - confluent

#   #####################
#   # 2. Airflow webserver
#   webserver:
#     image: apache/airflow:2.6.0-python3.9
#     command: webserver
#     entrypoint: ['/opt/airflow/script/entrypoint.sh']
#     depends_on:
#       - postgres
#     environment:
#       - EXECUTOR=Sequential
#       - AIRFLOW_DATABASE_URL=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
#       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgres+psycopg2://airflow:airflow@postgres:5432/airflow

#     logging:
#       options:
#         max-size: 10m
#         max-file: "3"
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./script/entrypoint.sh:/opt/airflow/script/entrypoint.sh
#       - ./requirements.txt:/opt/airflow/requirements.txt

#     ports:
#       - "8080:8080"

#     # healthcheck:
#     #   test: ["CMD-SHELL", "[-f /opt/airflow/airflow-webserver.pid]"]

#     #   test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
#     #   interval: 30s
#     #   timeout: 30s
#     #   retries: 3

#     # networks:
#     #   - confluent

#   #####################
#   # 3. Airflow scheduler
#   scheduler:
#     image: apache/airflow:2.6.0-python3.9
#     entrypoint: ['/opt/airflow/script/entrypoint.sh']
#     depends_on:
#       - webserver
#       # webserver:
#       #   condition: service_healthy
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./script/entrypoint.sh:/opt/airflow/script/entrypoint.sh
#       - ./requirements.txt:/opt/airflow/requirements.txt
      
#     environment:
#       - LOAD_EX=n
#       - EXECUTOR=Sequential
#       - AIRFLOW_DATABASE_SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
#       - AIRFLOW_WEBSERVER_SECRET_KEY=this_is_a_very_secured_key
#     command: ["/bin/bash", "-c", "pip install -r ./requirements.txt && airflow db upgrade  && airflow scheduler"]

#   # networks:
#   #   - confluent


# # network configuration on defualt setting
# networks:
#   default:
#     # driver: custom-driver-1



############
version: '3.8'
services:
  #########
  # 1. postgres
  postgres:
    image: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - "./postgres_db:/var/lib/postgresql/data:rw"

  #########
  # 2. scheduler
  scheduler:
    image: apache/airflow
    command: scheduler
    deploy:
      restart_policy:
        condition: on-failure
    depends_on:
      - webserver
    env_file:
      - .env 
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
  
  #########
  # 3. webserver
  webserver:
    image: apache/airflow
    entrypoint: ./script/entrypoint.sh

    deploy:
      restart_policy:
        condition: on-failure

    depends_on:
      - postgres
      # - scheduler
    env_file:
      - .env
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./script:/opt/airflow/script
    ports:
      - "8080:8080"


networks:
  default:
    # driver: custom-driver-1